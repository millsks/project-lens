# GitHub Copilot Instructions

This file provides guidance to GitHub Copilot when working with code in this repository.

## Project Context

LENS (Lineage & Enterprise eXplainer Service) is an open-source service that transforms technical lineage and metadata into human-readable explanations. It sits on top of existing data catalogs and lineage platforms, providing APIs to answer questions about data lineage, system dependencies, and impact analysis.

**Current Status**: Early exploratory phase - expect breaking changes to APIs and data structures.

## Architecture

LENS is organized into three main layers:

1. **Metadata Integration Layer**
   - Connectors to lineage stores (graph DB or vendor API)
   - Data catalog integrations
   - Optional report registries
   - Normalizes metadata into a simple graph model

2. **LENS Service API**
   - Stateless FastAPI service
   - Endpoints for lineage explanations and impact analysis
   - Orchestrates metadata retrieval, graph summarization, and LLM calls

3. **Client Integrations**
   - UI buttons/panels in existing catalog or lineage tools
   - Optional CLI or web UI

## Technology Stack

- **Language**: Python 3.12
- **Package Manager**: pixi (conda-based)
- **Build**: hatch with hatch-vcs (git-based versioning)
- **Web Framework**: FastAPI with uvicorn
- **Database**: PostgreSQL 16 + SQLAlchemy 2.0 + Alembic
- **Task Queue**: Celery + Flower
- **Message Broker**: Redis 7
- **Testing**: pytest, pytest-cov, pytest-asyncio
- **Code Quality**: ruff (lint/format), pyright (type checking)
- **Changelog**: git-cliff (conventional commits)

## Design Principles

- **Metadata-First**: Only works with metadata, never touches raw data
- **Adapter Pattern**: Integrates with existing tools via connectors/adapters
- **Stateless Service**: API designed to be stateless for easy horizontal scaling
- **Narrative Generation**: Converts technical graphs into human-readable explanations

## Code Style and Standards

### Python Style
- Follow PEP 8 with 100 character line length
- Use type hints consistently (pyright strict mode)
- Prefer pathlib over os.path
- Use async/await for I/O operations
- Format with ruff: `pixi run -e dev format`

### Testing
- Write tests for all new features
- Use pytest fixtures for common setup
- Async tests use pytest-asyncio
- Target meaningful coverage, not just high percentages
- Run tests: `pixi run -e dev test`

### Commit Messages
Use [Conventional Commits](https://www.conventionalcommits.org/):
- `feat:` - New features
- `fix:` - Bug fixes
- `docs:` - Documentation only
- `perf:` - Performance improvements
- `refactor:` - Code refactoring
- `style:` - Formatting, missing semicolons, etc.
- `test:` - Adding or updating tests
- `chore:` - Maintenance tasks
- `ci:` - CI/CD changes

Format: `type(optional-scope): description`

Example: `feat(api): add lineage explanation endpoint`

## Common Tasks

### Running the Application
```bash
# Start development server with auto-reload
pixi run dev
```

### Code Quality
```bash
# Format code
pixi run -e dev format

# Check linting
pixi run -e dev lint

# Type checking
pixi run -e dev typecheck
```

### Testing
```bash
# Run all tests
pixi run -e dev test

# Run with coverage
pixi run -e dev test-cov

# Run specific test file
pixi run -e dev pytest tests/test_main.py
```

### Docker Services
```bash
# Start PostgreSQL and Redis
pixi run docker-up

# Stop services
pixi run docker-down

# View logs
pixi run docker-logs

# Check service status
pixi run docker-ps
```

### Building
```bash
# Build Python package (wheel + sdist)
pixi run -e dev build-python
```

## Project Structure

```
src/lens/          - Main application code
  __init__.py      - Package initialization with version
  _version.py      - Auto-generated by hatch-vcs (git-ignored)
  main.py          - FastAPI application entry point

tests/             - Test suite
  __init__.py
  test_main.py     - FastAPI endpoint tests

pixi.toml          - Pixi config with tasks and dependencies
pyproject.toml     - Python project metadata and tool configs
docker-compose.yml - Local PostgreSQL and Redis services
.env.example       - Environment variables template
```

## Environment Setup

1. Install dependencies: `pixi install`
2. Copy environment config: `cp .env.example .env`
3. Start Docker services: `pixi run docker-up`
4. Run tests: `pixi run -e dev test`

**Note**: Most dev commands require the `dev` environment. Use `pixi run -e dev <command>` or activate the shell with `pixi shell -e dev`.

## Development Workflow

1. Create feature branch: `git checkout -b feat/your-feature`
2. Make changes following existing patterns
3. Run quality checks: format, lint, typecheck, test
4. Commit with conventional message
5. Push and create pull request

## Current Development Phase

**Completed**:
- ✅ Project structure and build configuration
- ✅ Development environment setup
- ✅ Docker services (PostgreSQL, Redis)
- ✅ Basic FastAPI application with health endpoints
- ✅ Testing framework
- ✅ Code quality tools
- ✅ Conventional commits and changelog automation

**Next Steps**:
1. Define core data models for lineage graphs
2. Implement database schema with Alembic migrations
3. Create metadata adapter interfaces
4. Develop API endpoints for lineage queries
5. Add LLM integration for narrative generation
6. Build example adapters for common tools

## Important Notes

- Version is dynamically generated from git tags (hatch-vcs)
- pixi.lock is marked as binary in .gitattributes
- Database credentials in .env.example are for development only
- LLM integration details are TBD
- Celery tasks are not yet implemented

## License

Apache-2.0
